
ğŸ“Š ClusterizaÃ§Ã£o de MunicÃ­pios do PiauÃ­ com K-Means

Este projeto utiliza tÃ©cnicas de aprendizado nÃ£o supervisionado para agrupar municÃ­pios do PiauÃ­ com base em indicadores educacionais. A metodologia aplicada envolve normalizaÃ§Ã£o dos dados, reduÃ§Ã£o de dimensionalidade (PCA) e clusterizaÃ§Ã£o (K-Means).
ğŸ“Œ Metodologia
ğŸ”¹ 1. PreparaÃ§Ã£o dos Dados

O objetivo Ã© agrupar municÃ­pios do PiauÃ­ considerando qualidade educacional (IDEB) e volume educacional (nÃºmero de matrÃ­culas e docentes).

No entanto, as mÃ©tricas utilizadas possuem escalas diferentes e outliers, o que pode afetar o modelo de clusterizaÃ§Ã£o. Para evitar distorÃ§Ãµes, aplicamos tÃ©cnicas de normalizaÃ§Ã£o e transformaÃ§Ã£o dos dados.
ğŸ”¹ 2. VariÃ¡veis Utilizadas

Foram consideradas as seguintes mÃ©tricas para a clusterizaÃ§Ã£o:

    Indicador de Desenvolvimento da EducaÃ§Ã£o BÃ¡sica (IDEB) - Ensino Fundamental
    NÃºmero de matrÃ­culas no ensino fundamental
    NÃºmero de matrÃ­culas no ensino mÃ©dio
    NÃºmero de docentes no ensino fundamental
    NÃºmero de docentes no ensino mÃ©dio

âš™ï¸ TransformaÃ§Ã£o das VariÃ¡veis
ğŸ“ˆ 2.1 NormalizaÃ§Ã£o do IDEB (IDEB Escalonado)

O IDEB foi padronizado utilizando o RobustScaler, que transforma os valores em relaÃ§Ã£o Ã  mediana e intervalo interquartil (IQR).

ğŸ”¹ FÃ³rmula aplicada:
IDEB Escalonado=(IDEBâˆ’Mediana(IDEB))/IQR(IDEB) 

ğŸ”¹ Por que usar essa normalizaÃ§Ã£o?

    O IDEB pode ter valores com baixa variaÃ§Ã£o, mas conter outliers.
    O escalonamento robusto reduz o impacto de valores extremos, mantendo a estrutura original dos dados.

ğŸ« 2.2 ConstruÃ§Ã£o do Ãndice de Volume (PCA)

As mÃ©tricas de volume (matrÃ­culas e docentes) possuem escalas muito diferentes. Para garantir comparabilidade, aplicamos trÃªs etapas:

1ï¸âƒ£ TransformaÃ§Ã£o LogarÃ­tmica (log1p)

    Reduz grandes variaÃ§Ãµes entre municÃ­pios grandes e pequenos.
    FÃ³rmula aplicada:
    xâ€²=logâ¡(1+x)

2ï¸âƒ£ Escalonamento Robusto (RobustScaler)

    Normaliza os valores das mÃ©tricas de matrÃ­cula/docentes com base na mediana e IQR.

3ï¸âƒ£ ReduÃ§Ã£o de Dimensionalidade (PCA - Principal Component Analysis)

    O PCA combina variÃ¡veis correlacionadas em um Ãºnico Ã­ndice, chamado Ãndice de Volume, que representa a variaÃ§Ã£o conjunta das mÃ©tricas educacionais.
    A primeira componente principal (PC1) captura a maior variaÃ§Ã£o dos dados.

ğŸ”¹ Por que usar PCA?
âœ… MatrÃ­culas e docentes sÃ£o altamente correlacionados.
âœ… O PCA reduz redundÃ¢ncia e melhora a eficiÃªncia do modelo.
ğŸ·ï¸ ClusterizaÃ§Ã£o com K-Means

Com as variÃ¡veis transformadas, aplicamos o algoritmo K-Means para segmentar os municÃ­pios.

ğŸ”¹ VariÃ¡veis utilizadas na clusterizaÃ§Ã£o:

    IDEB Escalonado (qualidade da educaÃ§Ã£o).
    Ãndice de Volume (PCA das matrÃ­culas e docentes) (tamanho do sistema educacional).

ğŸ”¹ Por que usar apenas essas duas variÃ¡veis?
âœ… Evita aumento desnecessÃ¡rio da complexidade do modelo.
âœ… MantÃ©m um equilÃ­brio entre qualidade (IDEB) e quantidade (Volume Index).
ğŸ“Œ Escolha do nÃºmero ideal de clusters (k)

Utilizamos o mÃ©todo do cotovelo, que analisa a variaÃ§Ã£o intra-cluster para determinar o valor ideal de k. O nÃºmero de clusters foi definido conforme a melhor separaÃ§Ã£o dos dados.
ğŸ“Š Resultados

ApÃ³s a clusterizaÃ§Ã£o:

    Criamos um arquivo CSV contendo:
    âœ… MunicÃ­pio
    âœ… Cluster atribuÃ­do
    âœ… Proximidade ao centro do cluster (distÃ¢ncia euclidiana ao centrÃ³ide)

    A proximidade mede quÃ£o representativo um municÃ­pio Ã© dentro do seu cluster.




4. InterpretaÃ§Ã£o dos Resultados

ApÃ³s a clusterizaÃ§Ã£o, Ã© importante interpretar a saÃ­da do modelo. A interpretaÃ§Ã£o envolve compreender as caracterÃ­sticas mÃ©dias de cada cluster e analisar a proximidade dos municÃ­pios aos centros dos clusters.
4.1 CaracterÃ­sticas MÃ©dias por Cluster

Uma forma de interpretar os clusters Ã© visualizar as mÃ©dias das variÃ¡veis dentro de cada cluster. AtravÃ©s da anÃ¡lise das mÃ©dias, podemos identificar a principal diferenÃ§a entre os clusters. Por exemplo, se um cluster tem um IDEB muito alto e um Ãndice de Volume grande, ele pode representar municÃ­pios com boa educaÃ§Ã£o e grande sistema educacional.

Exemplo de tabelas de mÃ©dias por cluster:


MÃ©dias por Cluster:
         IDEB_scaled  Volume_index
Cluster                           
0           0.516239     -1.319312
1           0.141026      3.433563
2          -0.028736      0.846913
3           1.111111      9.729542
4          -0.626126     -0.842809


InterpretaÃ§Ã£o:
Cluster 0: Desempenho educacional moderado, sistema educacional pequeno.
Cluster 1: Desempenho educacional abaixo da mÃ©dia, sistema educacional grande.
Cluster 2: Desempenho educacional ligeiramente abaixo da mÃ©dia, sistema educacional mÃ©dio.
Cluster 3: Desempenho educacional alto, sistema educacional muito grande.
Cluster 4: Desempenho educacional baixo, sistema educacional pequeno.

4.2 Proximidade dos Clusters (DistÃ¢ncia ao Centro)

A proximidade de um municÃ­pio ao centro do seu cluster pode ser calculada utilizando a distÃ¢ncia euclidiana. Quanto menor a distÃ¢ncia, mais representativo o municÃ­pio Ã© dentro do seu cluster.

A proximidade pode ser interpretada da seguinte forma:

    MunicÃ­pios prÃ³ximos ao centro de um cluster sÃ£o mais representativos daquele grupo.
    MunicÃ­pios mais distantes podem ser considerados outliers ou casos marginais.

4.3 Ajustando o NÃºmero de Clusters (k)

Decidir o nÃºmero ideal de clusters Ã© uma parte crucial da anÃ¡lise de K-Means. O MÃ©todo do Cotovelo jÃ¡ Ã© uma tÃ©cnica que vocÃª usou para escolher o valor de k, mas como ajustar esse nÃºmero?

    Aumentar k: Se vocÃª aumentar o nÃºmero de clusters, vocÃª pode obter grupos menores e mais especÃ­ficos, mas o modelo pode se tornar mais complexo e pode sobreajustar os dados (overfitting). AlÃ©m disso, a interpretaÃ§Ã£o de clusters menores pode ser mais difÃ­cil.

    Diminuir k: Se vocÃª diminuir o nÃºmero de clusters, o modelo pode comeÃ§ar a generalizar mais, criando grupos mais amplos. Isso pode ser bom para uma visÃ£o mais macro dos dados, mas pode perder nuances importantes dentro dos grupos.

Quando ajustar k?

    Se vocÃª notar que os clusters resultantes nÃ£o fazem sentido ou nÃ£o sÃ£o representativos, talvez seja hora de ajustar o nÃºmero de clusters.
    Aumentar k pode gerar divisÃµes mais especÃ­ficas, mas tambÃ©m mais complexas e com menor generalizaÃ§Ã£o.

ğŸ“š ReferÃªncias

ğŸ“– Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
ğŸ“– Johnson, R. A., & Wichern, D. W. (2007). Applied Multivariate Statistical Analysis (6Âª ed.). Pearson.
ğŸ“„ Medium â€“ Towards Data Science:
ğŸ”— Artigos sobre RobustScaler, transformaÃ§Ã£o logarÃ­tmica (log1p) e clusterizaÃ§Ã£o com K-Means.