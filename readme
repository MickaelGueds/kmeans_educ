
**Por que usar essa normaliza√ß√£o?**

- O IDEB pode ter valores com baixa varia√ß√£o, mas conter outliers.
- O escalonamento robusto reduz o impacto de valores extremos, mantendo a estrutura original dos dados.

### üè´ 2.2 Constru√ß√£o do √çndice de Volume (PCA)

As m√©tricas de volume (matr√≠culas e docentes) possuem escalas muito diferentes. Para garantir comparabilidade, aplicamos tr√™s etapas:

1. **Transforma√ß√£o Logar√≠tmica (log1p)**
   - Reduz grandes varia√ß√µes entre munic√≠pios grandes e pequenos.
   - **F√≥rmula aplicada:**
     ```
     x‚Ä≤ = log(1 + x)
     ```

2. **Escalonamento Robusto (RobustScaler)**
   - Normaliza os valores das m√©tricas de matr√≠cula/docentes com base na mediana e IQR.

3. **Redu√ß√£o de Dimensionalidade (PCA - Principal Component Analysis)**
   - O PCA combina vari√°veis correlacionadas em um √∫nico √≠ndice, chamado **√çndice de Volume**, que representa a varia√ß√£o conjunta das m√©tricas educacionais.
   - A primeira componente principal (PC1) captura a maior varia√ß√£o dos dados.

**Por que usar PCA?**
- ‚úÖ Matr√≠culas e docentes s√£o altamente correlacionados.
- ‚úÖ O PCA reduz redund√¢ncia e melhora a efici√™ncia do modelo.

## üè∑Ô∏è Clusteriza√ß√£o com K-Means

Com as vari√°veis transformadas, aplicamos o algoritmo K-Means para segmentar os munic√≠pios.

**Vari√°veis utilizadas na clusteriza√ß√£o:**
- **IDEB Escalonado** (qualidade da educa√ß√£o).
- **√çndice de Volume** (PCA das matr√≠culas e docentes) (tamanho do sistema educacional).

**Por que usar apenas essas duas vari√°veis?**
- ‚úÖ Evita aumento desnecess√°rio da complexidade do modelo.
- ‚úÖ Mant√©m um equil√≠brio entre qualidade (IDEB) e quantidade (Volume Index).

### üìå Escolha do n√∫mero ideal de clusters (k)

Utilizamos o m√©todo do cotovelo, que analisa a varia√ß√£o intra-cluster para determinar o valor ideal de `k`. O n√∫mero de clusters foi definido conforme a melhor separa√ß√£o dos dados.

## üìä Resultados

Ap√≥s a clusteriza√ß√£o:

- Criamos um arquivo CSV contendo:
  - ‚úÖ Munic√≠pio
  - ‚úÖ Cluster atribu√≠do
  - ‚úÖ Proximidade ao centro do cluster (dist√¢ncia euclidiana ao centr√≥ide)

A proximidade mede qu√£o representativo um munic√≠pio √© dentro do seu cluster.

## 4. Interpreta√ß√£o dos Resultados

Ap√≥s a clusteriza√ß√£o, √© importante interpretar a sa√≠da do modelo. A interpreta√ß√£o envolve compreender as caracter√≠sticas m√©dias de cada cluster e analisar a proximidade dos munic√≠pios aos centros dos clusters.

### 4.1 Caracter√≠sticas M√©dias por Cluster

Uma forma de interpretar os clusters √© visualizar as m√©dias das vari√°veis dentro de cada cluster. Atrav√©s da an√°lise das m√©dias, podemos identificar a principal diferen√ßa entre os clusters. Por exemplo, se um cluster tem um IDEB muito alto e um √çndice de Volume grande, ele pode representar munic√≠pios com boa educa√ß√£o e grande sistema educacional.

**Exemplo de tabelas de m√©dias por cluster:**

| Cluster | IDEB_scaled | Volume_index |
|---------|-------------|--------------|
| 0       | 0.516239    | -1.319312    |
| 1       | 0.141026    | 3.433563     |
| 2       | -0.028736   | 0.846913     |
| 3       | 1.111111    | 9.729542     |
| 4       | -0.626126   | -0.842809    |

**Interpreta√ß√£o:**
- **Cluster 0:** Desempenho educacional moderado, sistema educacional pequeno.
- **Cluster 1:** Desempenho educacional abaixo da m√©dia, sistema educacional grande.
- **Cluster 2:** Desempenho educacional ligeiramente abaixo da m√©dia, sistema educacional m√©dio.
- **Cluster 3:** Desempenho educacional alto, sistema educacional muito grande.
- **Cluster 4:** Desempenho educacional baixo, sistema educacional pequeno.

### 4.2 Proximidade dos Clusters (Dist√¢ncia ao Centro)

A proximidade de um munic√≠pio ao centro do seu cluster pode ser calculada utilizando a dist√¢ncia euclidiana. Quanto menor a dist√¢ncia, mais representativo o munic√≠pio √© dentro do seu cluster.

**A proximidade pode ser interpretada da seguinte forma:**
- Munic√≠pios pr√≥ximos ao centro de um cluster s√£o mais representativos daquele grupo.
- Munic√≠pios mais distantes podem ser considerados outliers ou casos marginais.

### 4.3 Ajustando o N√∫mero de Clusters (k)

Decidir o n√∫mero ideal de clusters √© uma parte crucial da an√°lise de K-Means. O M√©todo do Cotovelo j√° √© uma t√©cnica que voc√™ usou para escolher o valor de `k`, mas como ajustar esse n√∫mero?

- **Aumentar k:** Se voc√™ aumentar o n√∫mero de clusters, voc√™ pode obter grupos menores e mais espec√≠ficos, mas o modelo pode se tornar mais complexo e pode sobreajustar os dados (overfitting). Al√©m disso, a interpreta√ß√£o de clusters menores pode ser mais dif√≠cil.
- **Diminuir k:** Se voc√™ diminuir o n√∫mero de clusters, o modelo pode come√ßar a generalizar mais, criando grupos mais amplos. Isso pode ser bom para uma vis√£o mais macro dos dados, mas pode perder nuances importantes dentro dos grupos.

**Quando ajustar k?**
- Se voc√™ notar que os clusters resultantes n√£o fazem sentido ou n√£o s√£o representativos, talvez seja hora de ajustar o n√∫mero de clusters.
- Aumentar `k` pode gerar divis√µes mais espec√≠ficas, mas tamb√©m mais complexas e com menor generaliza√ß√£o.

## üìö Refer√™ncias

- üìñ Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- üìñ Johnson, R. A., & Wichern, D. W. (2007). *Applied Multivariate Statistical Analysis* (6¬™ ed.). Pearson.
- üìÑ Medium ‚Äì Towards Data Science:
  - üîó Artigos sobre `RobustScaler`, transforma√ß√£o logar√≠tmica (`log1p`) e clusteriza√ß√£o com K-Means.
